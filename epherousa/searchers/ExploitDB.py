# coding=utf-8
from __future__ import division, unicode_literals

import csv
import re
import sys
from bs4 import BeautifulSoup
from collections import Counter
from datetime import datetime
from requests.exceptions import RequestException, Timeout

from .common import Searcher, Exploit

"""
NOTE
 The "CVE Reference Map for Source EXPLOIT-DB"
 at https://cve.mitre.org/data/refs/refmap/source-EXPLOIT-DB.html
 appears to be missing lots of exploits before 2006 or something
"""


class ExploitDB(Searcher):
    """This classes searches for exploits at https://www.exploit-db.com/."""
    _URL = 'https://www.exploit-db.com{}'
    _EXPLOITDB_URL = _URL.format('/exploits/')
    _DB_URL = 'https://raw.githubusercontent.com/offensive-security/exploit-database/master/files.csv'
    _ID_TO_CVE_URL = 'https://cve.mitre.org/data/refs/refmap/source-EXPLOIT-DB.html'
    _DESCRIPTION = 'Searches for exploits at https://www.exploit-db.com'

    def setup(self, search_by_string=True):
        """Setup method used for initialisation purposes by every Scanner."""
        super(ExploitDB, self).setup()
        self.search_terms = []

        if search_by_string:
            for w in self.search_string.split():
                self.search_terms.append(w.lower().strip("*"))

        self._exploitDB = self.loaddb()

    def build_exploit(self, _exploit):
        """Builds the exploit object."""
        exploit = Exploit()
        exploit.date = datetime.strptime(_exploit[3], "%Y-%m-%d")
        exploit.desc = _exploit[2]
        exploit.url = self._EXPLOITDB_URL + _exploit[0]
        if self.cve:
            # if searching with CVE, return that one
            exploit.cve = self.cve
        else:
            # try to fetch the CVE from Exploit's page
            exploit.cve = self.fetch_cve(exploit)
        return exploit

    def fetch_cve(self, exploit):
        """Scraps Exploit-DBs website to fetch the exploit's CVE."""
        try:
            html = self.session.get(exploit.url)
            soup = BeautifulSoup(html.content, 'html.parser')
            start_table = soup.find_all('table', class_='exploit_list')
            cve = start_table[0].find_all('a', string=re.compile('CVE-\d{4}-\d{4,7}'))
            for i in cve:
                for j in i.contents:
                    if self._CVE_PATTERN.search(j):
                        return j.strip()
        except Timeout as e:
            self.log.warn("Timed out while requesting {}: {}".format(exploit.url, e))
            return "N/A"

        return "N/A"

    def find_exploits_by_cve(self):
        """Searches for exploits using a CVE number."""
        self.exp_id = self.map_cve_to_exploitdb()

        for exp in csv.reader(self._exploitDB):
            if self.exp_id and exp[0] == self.exp_id and len(self.exploits) < self.limit:
                self.exploits.append(self.build_exploit(exp))

    def rank_search_term(self, term):
        """Returns the frequency rate of each user provided term."""
        # if term never shows up in exploit-db descriptions
        if self.w_freq[term] == 0:
            # give this term full weight
            return 1
        return 1 / self.w_freq[term]

    def find_exploits_by_string(self):
        """Searches for exploits using the user's string input."""
        _exploits = []
        for exp in csv.reader(self._exploitDB):
            for w in exp[2].split():
                w.lower()

        self.w_freq = Counter([w.lower() for exp in csv.reader(self._exploitDB) for w in exp[2].split()])
        # find all relevant exploits sorting by most relevant
        for exp in csv.reader(self._exploitDB):
            cnt = 0
            # compare each word in exploit desc with user search terms
            for term in self.search_terms:
                # keep the unique lower cased words from ExploitDB descriptions
                desc_word_list = [{word.lower() for word in exp[2].split()}]
                for word in desc_word_list:
                    if term.lower() in word:
                        cnt += (1 * self.rank_search_term(term))

            # add into the list if at least 1 word was found
            if cnt > 0:
                _exploits.append((cnt, exp))

        # sort in DESC mode
        temp_exploits = [exp[1] for exp in sorted(_exploits, key=lambda tup: tup[0], reverse=True)]
        self.log.debug('Sorting exploits')

        if self.limit > 0:
            for exp in temp_exploits[:self.limit]:
                self.exploits.append(self.build_exploit(exp))
        else:
            for exp in temp_exploits:
                self.exploits.append(self.build_exploit(exp))

    def map_cve_to_exploitdb(self):
        """Maps CVE numbers to Exploit-DB's IDs scrapping an online map table."""
        try:
            self.log.info('Requesting {}'.format(self._ID_TO_CVE_URL))
            html = self.session.get(self._ID_TO_CVE_URL)
            soup = BeautifulSoup(html.content, 'html.parser')
            ids = soup.find_all('td', string=re.compile('EXPLOIT-DB:'))
            for _id in ids:
                # Keep the ID numeric value out of the whole EXPLOIT-DB:<ID> text
                try:
                    exploit_id = int(re.findall('\d+', str(_id))[0])
                except TypeError as e:
                    self.log.warn('Failed to convert exploit-db ID to integer: {}'.format(e))
                    sys.exit(1)
                # Ugly way to keep only the CVEs from soup's returning list which
                # includes newline and whitespace elements also
                if self.cve in [i for i in (_id.find_next().find_all(string=True)) if len(i) > 2]:
                    return str(exploit_id)
            # No Match found
            return False

        except Timeout as e:
            self.log.info('Requesting {} timed out.. with error: {}'.format(self._ID_TO_CVE_URL, e))
            return False
        except RequestException as e:
            self.log.info('Failed to access: {}. Error: {}'.format(self._ID_TO_CVE_URL, e))
            return False

    def loaddb(self):
        """Loads the Exploit-DB's CSV database from the relevant git repo."""

        try:
            self.log.info('Requesting {}'.format(self._DB_URL))
            download = self.session.get(self._DB_URL)
            dec_content = download.content.decode('utf-8').strip()
            return dec_content.splitlines()
        except RequestException as e:
            # maybe make a die() method for all these prints+exits
            # or handle exceptions in a more graceful way
            self.log.critical('Failed to download exploit-db database: {}'.format(e))
            sys.exit(1)
        except csv.Error as e:
            self.log.critical('Failed to process exploit-db database as CSV: {}'.format(e))
            sys.exit(1)
